{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credits\n",
    "\n",
    "This is heavily based on https://github.com/pytorch/tutorials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is PyTorch?\n",
    "\n",
    "> **NOTE** In the last part of this lab cuda is used.\n",
    "\n",
    "\n",
    "PyTorch a Python based scientific computing package targeted at two sets of\n",
    "audiences:\n",
    "-  A replacement for numpy to use the power of GPUs\n",
    "-  a deep learning research platform that provides maximum flexibility and speed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started\n",
    "\n",
    "In this lab you will get a quick start on what pytorch is and how to use it.\n",
    "\n",
    "## 1. Tensors\n",
    "\n",
    "Tensors are similar to numpyâ€™s ndarrays, with the addition being that\n",
    "Tensors can also be used on a GPU to accelerate computing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct a $5\\times 3$ matrix, uninitialized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x = torch.Tensor(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct a randomly initialized matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get its size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: `torch.Size` is in fact a tuple, so it supports the same operations that a tuple supports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[1:3] = 2\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment\n",
    "\n",
    "Make use of the pytorch docs <http://pytorch.org/docs/torch>\n",
    "1. Make a tensor of size (2, 17)\n",
    "2. Make a torch.FloatTensor of size (3, 1)\n",
    "3. Make a torch.LongTensor of size (5, 2, 1)\n",
    "  - fill the entire tensor with 7s\n",
    "4. Make a torch.ByteTensor of size (5,)\n",
    "  - fill the middle 3 indices with ones such that it records [0, 1, 1, 1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solutions: Tensors Assignment\n",
    "import torch\n",
    "\n",
    "# 1) Tensor of size (2, 17)\n",
    "t1 = torch.empty(2, 17)\n",
    "print(\"Tensor (2,17):\")\n",
    "print(t1)\n",
    "\n",
    "# 2) torch.FloatTensor of size (3, 1)\n",
    "t2 = torch.FloatTensor(3, 1)\n",
    "print(\"\\nFloatTensor (3,1):\")\n",
    "print(t2)\n",
    "\n",
    "# 3) torch.LongTensor of size (5, 2, 1) filled with 7s\n",
    "# Prefer stable constructor using dtype\n",
    "t3 = torch.full((5, 2, 1), 7, dtype=torch.long)\n",
    "print(\"\\nLongTensor (5,2,1) filled with 7s:\")\n",
    "print(t3)\n",
    "\n",
    "# 4) torch.ByteTensor of size (5,) with [0, 1, 1, 1, 0]\n",
    "# torch.uint8 is the dtype behind ByteTensor\n",
    "t4 = torch.zeros(5, dtype=torch.uint8)\n",
    "t4[1:4] = 1\n",
    "print(\"\\nByteTensor (5,) with middle ones:\")\n",
    "print(t4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Operations\n",
    "There are multiple syntaxes for operations. Let's see addition as an example:\n",
    "\n",
    "### 2.1 Addition: syntax 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.rand(5, 3)\n",
    "print(x + y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Addition: syntax 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.add(x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Addition: giving an output tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = torch.Tensor(5, 3)\n",
    "torch.add(x, y, out=result)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Addition: in-place\n",
    "\n",
    "adds `x` to `y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.add_(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: Any operation that mutates a tensor in-place is post-fixed with an `_`. For example: `x.copy_(y)`, `x.t_()`, will change `x`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use standard numpy-like indexing with all bells and whistles!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read later**: 100+ Tensor operations, including transposing, indexing, slicing, mathematical operations, linear algebra, random numbers, etc are described here <http://pytorch.org/docs/torch>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment\n",
    "\n",
    "1. multiplication of two tensors (see [torch.Tensor.mul](http://pytorch.org/docs/master/tensors.html#torch.Tensor.mul))\n",
    "2. do the same, but inplace\n",
    "3. division of two tensors (see [torch.Tensor.div](http://pytorch.org/docs/master/tensors.html#torch.Tensor.div))\n",
    "4. perform a matrix multiplication of two tensors of size (2, 4) and (4, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solutions: Operations Assignment\n",
    "import torch\n",
    "\n",
    "# Prepare sample tensors\n",
    "x = torch.rand(5, 3)\n",
    "y = torch.rand(5, 3)\n",
    "print(\"x:\\n\", x)\n",
    "print(\"\\ny:\\n\", y)\n",
    "\n",
    "# 1) Multiplication of two tensors (elementwise)\n",
    "mul_res = x * y\n",
    "print(\"\\nElementwise multiplication (x * y):\\n\", mul_res)\n",
    "\n",
    "# 2) In-place multiplication\n",
    "y_inplace = y.clone()\n",
    "y_inplace.mul_(x)\n",
    "print(\"\\nIn-place multiplication (y.mul_(x)):\\n\", y_inplace)\n",
    "\n",
    "# 3) Division of two tensors (elementwise)\n",
    "div_res = x / (y + 1e-8)  # add small epsilon to avoid division by zero\n",
    "print(\"\\nElementwise division (x / y):\\n\", div_res)\n",
    "\n",
    "# 4) Matrix multiplication of (2,4) and (4,2)\n",
    "a = torch.rand(2, 4)\n",
    "b = torch.rand(4, 2)\n",
    "matmul_res = torch.matmul(a, b)\n",
    "print(\"\\nMatrix multiplication (2x4) @ (4x2):\\n\", matmul_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Numpy Bridge\n",
    "\n",
    "Converting a torch Tensor to a numpy array and vice versa is a breeze.\n",
    "\n",
    "The torch Tensor and numpy array will share their underlying memory locations, and changing one will change the other.\n",
    "\n",
    "### 3.1 Converting torch Tensor to numpy Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.ones(5)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = a.numpy()\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See how the numpy array changed in value: the `numpy()` method provides a *view* of the original tensor, not a copy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.add_(1)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Converting numpy Array to torch Tensor\n",
    "\n",
    "See how changing the np array changed the torch Tensor automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "np.add(a, 1, out=a)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment\n",
    "\n",
    "1. create a tensor of size (5, 2) containing ones\n",
    "2. now convert it to a NumPy array\n",
    "3. now convert it back to a torch tensor\n",
    "\n",
    "All the Tensors on the CPU except a CharTensor support converting to NumPy and back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solutions: Numpy Bridge Assignment\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# 1) Create a tensor of size (5, 2) containing ones\n",
    "t_ones = torch.ones(5, 2)\n",
    "print(\"Tensor ones (5,2):\\n\", t_ones)\n",
    "\n",
    "# 2) Convert it to a NumPy array\n",
    "np_arr = t_ones.numpy()\n",
    "print(\"\\nConverted to NumPy array:\\n\", np_arr)\n",
    "print(\"NumPy dtype:\", np_arr.dtype)\n",
    "\n",
    "# 3) Convert back to a torch tensor\n",
    "t_back = torch.from_numpy(np_arr)\n",
    "print(\"\\nConverted back to torch tensor:\\n\", t_back)\n",
    "print(\"Torch dtype:\", t_back.dtype)\n",
    "\n",
    "# Demonstrate shared memory (changing numpy updates torch)\n",
    "np_arr += 2\n",
    "print(\"\\nAfter np_arr += 2:\\nNumPy:\\n\", np_arr)\n",
    "print(\"Torch view:\\n\", t_back)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 CUDA Tensors\n",
    "\n",
    "Tensors can be moved onto GPU using the `.cuda` function.\n",
    "This is not necessary, but check the `README.md` for details on how to use a GPU with docker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us run this cell only if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    x = x.cuda()\n",
    "    y = y.cuda()\n",
    "    z = x + y\n",
    "    # Notice that the tensors are now of type torch.cuda.FloatTensor (notice the cuda in there)\n",
    "    # This is meant as a tensor to be run on the GPU.\n",
    "    # The .cuda() does this to any parameter it is applied to.\n",
    "    print(x)\n",
    "    print(y)\n",
    "    print(z)\n",
    "else:\n",
    "    print(\"CUDA not available on your machine.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
